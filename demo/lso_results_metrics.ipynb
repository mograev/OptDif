{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdfc132",
   "metadata": {},
   "source": [
    "# LSO Results Metrics\n",
    "\n",
    "This notebook computes and compares metrics for latent and LoRA space optimization results.\n",
    "\n",
    "The first part of this notebook implements the general metric functionalities, while the second part creates visualizations specifically for the experiment results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a61126",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7aae1f",
   "metadata": {},
   "source": [
    "### Results Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4176cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"../results\").expanduser().resolve()\n",
    "\n",
    "def get_result_dir(version : str, seed : int) -> Path:\n",
    "    \"\"\"\n",
    "    Return the path to the first main.log that matches the seed.\n",
    "    Allowed directory names:\n",
    "      <version>_<seed>\n",
    "      <version>_<seed>_<anything>\n",
    "    \"\"\"\n",
    "    # exact match first (no job-id)\n",
    "    exact = BASE_DIR / f\"{version}_{seed}\"\n",
    "    if exact.is_dir():\n",
    "        return exact\n",
    "\n",
    "    # wildcard for any trailing underscore / job-id\n",
    "    pattern = f\"{version}_{seed}_*/\"\n",
    "    matches = sorted(BASE_DIR.glob(pattern))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No log found for seed {seed} under {BASE_DIR}\")\n",
    "    return matches[-1]  # return the most recent match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7237ea",
   "metadata": {},
   "source": [
    "### Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57975d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "_iter_re = re.compile(r\"iter_(\\d+)\")\n",
    "\n",
    "def iter_num_from_path(p: Path) -> int:\n",
    "\tm = _iter_re.search(str(p))\n",
    "\treturn int(m.group(1)) if m else -1\n",
    "\n",
    "def natural_name_key(name: str):\n",
    "\tparts = re.split(r\"(\\d+)\", name)\n",
    "\treturn [int(s) if s.isdigit() else s for s in parts]\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "\t\"\"\"\n",
    "\tLoads all img images that live under the provided root directory.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, version, seed, subdir=\"img_opt\", transform=None, iteration_min=0, iteration_max=500):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tversion (str): Parent directory that contains data/samples.\n",
    "\t\t\tsubdir (str): Subdirectory under data/samples to look for images.\n",
    "\t\t\ttransform (Optional[Any]): Optional torchvision/Albumentations transform applied to the PIL image.\n",
    "\t\t\titeration_min (int): Minimum number of iterations to consider.\n",
    "\t\t\titeration_max (int): Maximum number of iterations to consider.\n",
    "\t\t\"\"\"\n",
    "\t\tself.root = get_result_dir(version, seed=seed)\n",
    "\t\tself.transform = transform\n",
    "\t\tself.iteration_min = iteration_min\n",
    "\t\tself.iteration_max = iteration_max\n",
    "\n",
    "\t\t# Collect all files\n",
    "\t\tall_files = list(self.root.glob(f\"data/samples/iter_*/{subdir}/*.png\"))\n",
    "\n",
    "\t\t# Keep only files from iterations <= iteration_max and >= iteration_min\n",
    "\t\tall_files = [p for p in all_files if self.iteration_min <= iter_num_from_path(p) <= self.iteration_max]\n",
    "\n",
    "\t\t# Sort by (iteration number, filename natural order)\n",
    "\t\tself.files = sorted(\n",
    "\t\t\tall_files,\n",
    "\t\t\tkey=lambda p: (iter_num_from_path(p), natural_name_key(p.name))\n",
    "\t\t)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.files)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = self.files[idx]\n",
    "\t\timage = Image.open(img_path).convert(\"RGB\")\n",
    "\t\tif self.transform is not None:\n",
    "\t\t\timage = self.transform(image)\n",
    "\n",
    "\t\treturn image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90f9619",
   "metadata": {},
   "source": [
    "## Fréchet Inception Distance (FID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.metrics.fid import FIDScore\n",
    "\n",
    "def get_fid_score(version, seeds=[42, 43, 44], iteration_min=0, iteration_max=500):\n",
    "    \"\"\"\n",
    "    Compute the Fréchet Inception Distance (FID) score for a given version.\n",
    "    Args:\n",
    "        version (str): the version identifier for the model.\n",
    "        seeds (list): List of random seeds to use for evaluation.\n",
    "        iteration_min (int): Minimum number of iterations to consider.\n",
    "        iteration_max (int): Maximum number of iterations to consider.\n",
    "    Returns:\n",
    "        float: The computed FID score.\n",
    "        float: The standard deviation of the FID score across seeds.\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []\n",
    "    for seed in seeds:\n",
    "        # Get the result directory for the given version and seed\n",
    "        result_dir = get_result_dir(version, seed)\n",
    "\n",
    "        # Load hparams yaml\n",
    "        hparams = yaml.safe_load(open(result_dir / \"hparams.yaml\", 'r'))\n",
    "\n",
    "        # Derive min and max property range (that has not been seen during optimization)\n",
    "        opt_min = int(hparams['max_property_value'])\n",
    "        opt_max = 5\n",
    "\n",
    "        # Derive image size\n",
    "        if version.startswith(\"ex4_sdxl\"):\n",
    "            img_size = 1024\n",
    "        elif version.startswith(\"ex4\"):\n",
    "            img_size = 512\n",
    "        else:\n",
    "            img_size = 256\n",
    "\n",
    "        # Load optimized images as dataset\n",
    "        img_opt_dataset = ImgDataset(\n",
    "            version=version,\n",
    "            seed=seed,\n",
    "            subdir=\"img_opt\",\n",
    "            transform=transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ]),\n",
    "            iteration_min=iteration_min,\n",
    "            iteration_max=iteration_max\n",
    "        )\n",
    "\n",
    "        # Initialize FID instance\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        fid_instance = FIDScore(img_size=img_size, device=device, num_workers=0)\n",
    "\n",
    "        # Load real statistics\n",
    "        fid_instance.load_real_stats(f\"../data/ffhq/inception_stats/size_{img_size}_smile_{opt_min}_{opt_max}.pt\")\n",
    "\n",
    "        # Compute FID score for the optimized images\n",
    "        fid_score = fid_instance.compute_score_from_data(img_opt_dataset)\n",
    "\n",
    "        scores.append(float(fid_score))\n",
    "\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14853b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fid_score(version=\"ex4_sdxl_gbo\", seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381e3d2",
   "metadata": {},
   "source": [
    "## Perceptual Similarity (LPIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4232a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from taming.modules.losses.lpips import LPIPS\n",
    "\n",
    "# Initialize LPIPS instance\n",
    "lpips = LPIPS().eval()\n",
    "\n",
    "def get_lpips_score(version, seeds=[42, 43, 44], iteration_min=0, iteration_max=500):\n",
    "\t\"\"\"\n",
    "\tCompute the Learned Perceptual Image Patch Similarity (LPIPS) score for a given version.\n",
    "\tArgs:\n",
    "\t\tversion (str): the version identifier for the model.\n",
    "\t\tseeds (list): List of random seeds to use for evaluation.\n",
    "\t\titeration_min (int): Minimum number of iterations to consider.\n",
    "\t\titeration_max (int): Maximum number of iterations to consider.\n",
    "\tReturns:\n",
    "\t\tfloat: LPIPS score.\n",
    "\t\tfloat: Standard deviation of LPIPS score.\n",
    "\t\"\"\"\n",
    "\t# Move LPIPS to the appropriate device\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tlpips.to(device)\n",
    "\n",
    "\tscores = []\n",
    "\tfor seed in seeds:\n",
    "\t\t# Get the result directory for the given version and seed\n",
    "\t\tresult_dir = get_result_dir(version, seed)\n",
    "\n",
    "\t\t# Load hparams yaml\n",
    "\t\thparams = yaml.safe_load(open(result_dir / \"hparams.yaml\", 'r'))\n",
    "\n",
    "\t\t# Load optimized images as dataset\n",
    "\t\timg_opt_dataset = ImgDataset(\n",
    "\t\t\tversion=version,\n",
    "\t\t\tseed=seed,\n",
    "\t\t\tsubdir=\"img_opt\",\n",
    "\t\t\ttransform=transforms.Compose([\n",
    "\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\t\t\t]),\n",
    "\t\t\titeration_min=iteration_min,\n",
    "\t\t\titeration_max=iteration_max\n",
    "\t\t)\n",
    "\n",
    "\t\t# Load original images as dataset\n",
    "\t\timg_orig_dataset = ImgDataset(\n",
    "\t\t\tversion=version,\n",
    "\t\t\tseed=seed,\n",
    "\t\t\tsubdir=\"img_orig\",\n",
    "\t\t\ttransform=transforms.Compose([\n",
    "\t\t\t\ttransforms.ToTensor(),\n",
    "\t\t\t\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\t\t\t]),\n",
    "\t\t\titeration_min=iteration_min,\n",
    "\t\t\titeration_max=iteration_max\n",
    "\t\t)\n",
    "\n",
    "\t\t# Convert datasets to tensors\n",
    "\t\timg_opt_dataset = torch.stack([img for img in img_opt_dataset], dim=0).to(device)\n",
    "\t\timg_orig_dataset = torch.stack([img for img in img_orig_dataset], dim=0).to(device)\n",
    "\n",
    "\t\t# Compute LPIPS score for the optimized images\n",
    "\t\tlpips_score = lpips(img_opt_dataset, img_orig_dataset).mean().cpu().item()\n",
    "\t\tscores.append(float(lpips_score))\n",
    "\n",
    "\treturn np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lpips_score(version=\"ex4_sdxl_gbo\", seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f7b91",
   "metadata": {},
   "source": [
    "## TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fa872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_k(k, version, seeds=[42, 43, 44], iteration_max=500):\n",
    "    \"\"\"\n",
    "    Compute the Top-K smile score (mean ± std over seeds).\n",
    "    Args:\n",
    "        k (int) : K in “Top-K”.\n",
    "        version (str) : Model/version identifier.\n",
    "        seeds (iterable[int]) : Random seeds to aggregate over.\n",
    "        iteration_max (int) : Max evaluations to consider.\n",
    "    Returns:\n",
    "        tuple(float, float): (mean_topk, std_topk) across the given seeds.\n",
    "    \"\"\"\n",
    "    topk_vals = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        # Load the result file\n",
    "        result_file = get_result_dir(version, seed) / \"results.npz\"\n",
    "        results = np.load(result_file, allow_pickle=True)\n",
    "\n",
    "        # Smile scores from iteration 1 to iteration_max\n",
    "        scores = results[\"opt_point_properties\"][:iteration_max]\n",
    "\n",
    "        # Sort descending and pick the K-th best (account for short runs)\n",
    "        k_idx = min(k, len(scores)) - 1\n",
    "        topk = np.sort(scores)[::-1][k_idx]\n",
    "        topk_vals.append(topk)\n",
    "\n",
    "    mean_topk = float(np.mean(topk_vals))\n",
    "    std_topk  = float(np.std(topk_vals))\n",
    "\n",
    "    return mean_topk, std_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4647e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_k(k=10, version=\"ex4_sdxl_gbo\", seeds=[42, 43, 44], iteration_max=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af2f75",
   "metadata": {},
   "source": [
    "## Mean Smile Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_smile_score(version, seeds=[42, 43, 44], iteration_max=500):\n",
    "    \"\"\"\n",
    "    Compute the smile score mean and std for a given version and seeds.\n",
    "    Args:\n",
    "        version (str): the version identifier for the model.\n",
    "        seeds (list): list of seeds to quantify variability.\n",
    "        iteration_max (int): Maximum number of iterations to consider for the smile score.\n",
    "    Returns:\n",
    "        float: Mean smile score\n",
    "        float: Std smile score\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the results for the specified version and seeds\n",
    "    scores = []\n",
    "    for seed in seeds:\n",
    "        # Load results dictionary\n",
    "        result_file = get_result_dir(version, seed) / \"results.npz\"\n",
    "        results = np.load(result_file, allow_pickle=True)\n",
    "\n",
    "\t\t# Get smile scores\n",
    "        opt_point_properties = results['opt_point_properties']\n",
    "        opt_point_properties = opt_point_properties[:iteration_max]\n",
    "        scores.append(opt_point_properties.mean(axis=0))\n",
    "\n",
    "    # Compute mean and std\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "\n",
    "    return mean_score, std_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_smile_score(version=\"ex4_sdxl_gbo\", seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc312b",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ced5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def get_log_time(version, operation, seeds=[42, 43, 44]):\n",
    "\t\"\"\"\n",
    "\tCompute per-run mean time, then the grand mean ± std across runs.\n",
    "\t\"\"\"\n",
    "\tif operation == \"train\":\n",
    "\t\tline_re = re.compile(r\"\\b\\w+\\s+train done in ([\\d.]+)s\")\n",
    "\telif operation == \"opt\":\n",
    "\t\tline_re = re.compile(r\"\\b\\w+\\s+opt done in ([\\d.]+)s\")\n",
    "\telse:\n",
    "\t\traise ValueError(f\"Unknown operation type: {operation}\")\n",
    "\n",
    "\tmean_times = []\n",
    "\tfor seed in seeds:\n",
    "\t\tlog_path = get_result_dir(version, seed) / \"main.log\"\n",
    "\n",
    "\t\twith open(log_path, 'r') as f:\n",
    "\t\t\tlines = f.readlines()\n",
    "\n",
    "\t\ttimes = []\n",
    "\t\tfor line in lines:\n",
    "\t\t\tmatch = line_re.search(line)\n",
    "\t\t\tif match:\n",
    "\t\t\t\ttimes.append(float(match.group(1)))\n",
    "\n",
    "\t\tif not times:\n",
    "\t\t\traise ValueError(f\"No time found in log for seed {seed}\")\n",
    "\n",
    "\t\tmean_times.append(np.mean(times))\n",
    "\n",
    "\t# Compute mean and std across all seeds\n",
    "\tmean_time = np.mean(mean_times)\n",
    "\tstd_time = np.std(mean_times)\n",
    "\n",
    "\treturn mean_time, std_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_time(version=\"ex4_sdxl_gbo\", operation=\"opt\", seeds=[42, 43, 44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f598281",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611a3a4",
   "metadata": {},
   "source": [
    "## Experiment 1 (SD-VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02440a",
   "metadata": {},
   "source": [
    "### Original vs. Initial smile score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5efaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = []\n",
    "initial = []\n",
    "\n",
    "for seed in [42, 43, 44]:\n",
    "\tfor comb in [\n",
    "\t\t\"gp_train_lbfgsb\", \"gp_train_lbfgsb_pca\", \"gp_train_lbfgsb_fi\",\n",
    "\t\t\"dngo_train_lbfgsb\", \"dngo_train_lbfgsb_pca\", \"dngo_train_lbfgsb_fi\",\n",
    "\t\t\"gp_train_trustconstr\", \"gp_train_trustconstr_pca\", \"gp_train_trustconstr_fi\",\n",
    "\t\t\"dngo_train_trustconstr\", \"dngo_train_trustconstr_pca\", \"dngo_train_trustconstr_fi\",\n",
    "\t\t\"gp_train_trustconstrgmm_pca\", \"gp_train_trustconstrgmm_fi\",\n",
    "\t\t\"dngo_train_trustconstrgmm_pca\", \"dngo_train_trustconstrgmm_fi\",\n",
    "\t\t\"gbo_train\", \"gbo_train_pca\", \"gbo_train_fi\",\n",
    "\t]:\n",
    "\t\t# Get the result directory for the current combination\n",
    "\t\tresult_dir = get_result_dir(f\"ex1_sd35_{comb}\", seed=seed)\n",
    "\n",
    "\t\t# Load the results file\n",
    "\t\tscores_file = np.load(result_dir / \"results.npz\")\n",
    "\n",
    "\t\t# Get the original and initial smile scores of the first iteration\n",
    "\t\toriginal.extend(scores_file['orig_point_properties'][:5].tolist())\n",
    "\t\tinitial.extend(scores_file['init_point_properties'][:5].tolist())\n",
    "\n",
    "print(f\"Number of smile scores: {len(original)}\")\n",
    "print(f\"Original smile scores: {np.mean(original):.2f} ± {np.std(original):.2f}\")\n",
    "print(f\"Initial smile scores: {np.mean(initial):.2f} ± {np.std(initial):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b0dd2",
   "metadata": {},
   "source": [
    "## Experiment 3 (LatentVQVAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b7cc2",
   "metadata": {},
   "source": [
    "### Top10 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex3_dngo_train_lbfgsb\": \"DNGO\",\n",
    "\t\"ex3_gp_train_lbfgsb\": \"SparseGP\",\n",
    "\t\"ex3_gbo_train\": \"GBO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 100\n",
    "top_k = 10\n",
    "x_axis = list(range(5, max_iterations+5, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_top_k(top_k, version, seeds=[42, 43, 44], iteration_max=it)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('Top10 score')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axhline(y=2, color='gray', linestyle='--', label='Input Max')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex3_top10_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16970ab3",
   "metadata": {},
   "source": [
    "## Experiment 4 (LoRAdapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf626062",
   "metadata": {},
   "source": [
    "### SD1.5 & SDXL Top10 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019db0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex4_sd15_gp_style\": \"SD1.5 SparseGP\",\n",
    "\t\"ex4_sdxl_gp\": \"SDXL SparseGP\",\n",
    "\t\"ex4_sd15_dngo_style\": \"SD1.5 DNGO\",\n",
    "\t\"ex4_sdxl_dngo\": \"SDXL DNGO\",\n",
    "\t\"ex4_sd15_gbo_style\": \"SD1.5 GBO\",\n",
    "\t\"ex4_sdxl_gbo\": \"SDXL GBO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 100\n",
    "top_k = 10\n",
    "x_axis = list(range(5, max_iterations+5, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_top_k(top_k, version, seeds=[42, 43, 44], iteration_max=it)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tif idx % 2 == 0:\n",
    "\t\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx // 2}\")\n",
    "\telse:\n",
    "\t\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx // 2}\", linestyle=\"--\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx // 2}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('Top10 score')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axhline(y=2, color='gray', linestyle='--', label='Input Max')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex4_top10_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a62ce",
   "metadata": {},
   "source": [
    "### Retraining Top10 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex4_sd15_dngo_long\": \"w/o Retraining\",\n",
    "\t\"ex4_sd15_dngo_long_retrain\": \"w/ Retraining\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 500\n",
    "top_k = 50\n",
    "x_axis = list(range(5, max_iterations+5, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_top_k(top_k, version, seeds=[42, 43, 44], iteration_max=it)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('Top50 score')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axhline(y=2, color='gray', linestyle='--', label='Input Max')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex4_retraining_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f4190",
   "metadata": {},
   "source": [
    "## Experiment 5 (Comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ed190",
   "metadata": {},
   "source": [
    "### Top10 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex5_sd35_dngo_long\": \"LSO-SD\",\n",
    "\t\"ex5_latentvqvae_dngo_long\": \"LSO-LatentVQVAE\",\n",
    "\t\"ex4_sd15_dngo_long\": \"LoRASO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 500\n",
    "top_k = 10\n",
    "x_axis = list(range(5, max_iterations+5, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_top_k(top_k, version, seeds=[42, 43, 44], iteration_max=it)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('Top10 score')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axhline(y=2, color='gray', linestyle='--', label='Input Max')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex5_top10_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68be31",
   "metadata": {},
   "source": [
    "### Top50 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex5_sd35_dngo_long\": \"LSO-SD\",\n",
    "\t\"ex5_latentvqvae_dngo_long\": \"LSO-LatentVQVAE\",\n",
    "\t\"ex4_sd15_dngo_long\": \"LoRASO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 500\n",
    "top_k = 50\n",
    "x_axis = list(range(5, max_iterations+5, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_top_k(top_k, version, seeds=[42, 43, 44], iteration_max=it)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('Top50 score')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.axhline(y=2, color='gray', linestyle='--', label='Input Max')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex5_top50_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2c7b4",
   "metadata": {},
   "source": [
    "### FID evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex5_sd35_dngo_long\": \"LSO-SD\",\n",
    "\t\"ex5_latentvqvae_dngo_long\": \"LSO-LatentVQVAE\",\n",
    "\t\"ex4_sd15_dngo_long\": \"LoRASO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 500\n",
    "x_axis = list(range(5, max_iterations+1, 50))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_fid_score(version, seeds=[42, 43, 44], iteration_min=0, iteration_max=it-5)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('FID score')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex5_fid_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29257f67",
   "metadata": {},
   "source": [
    "### LPIPS evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48947b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "version_dict = {\n",
    "\t\"ex5_sd35_dngo_long\": \"LSO-SD\",\n",
    "\t\"ex5_latentvqvae_dngo_long\": \"LSO-LatentVQVAE\",\n",
    "\t\"ex4_sd15_dngo_long\": \"LoRASO\",\n",
    "}\n",
    "\n",
    "result_dict = {}\n",
    "max_iterations = 500\n",
    "x_axis = list(range(5, max_iterations+1, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "\n",
    "for idx, (version, version_name) in enumerate(version_dict.items()):\n",
    "\n",
    "\tmean_list, var_list = [], []\n",
    "\tfor it in x_axis:\n",
    "\t\tm, v = get_lpips_score(version, seeds=[42, 43, 44], iteration_min=it-5, iteration_max=it-5)\n",
    "\n",
    "\t\tmean_list.append(m)\n",
    "\t\tvar_list.append(v)\n",
    "\n",
    "\t# Convert to arrays\n",
    "\tmean_arr = np.array(mean_list)\n",
    "\tvar_arr = np.array(var_list)\n",
    "\n",
    "\tax.plot(x_axis, mean_arr, label=f'{version_name}', color=f\"C{idx}\")\n",
    "\tax.fill_between(x_axis, mean_arr-var_arr, mean_arr+var_arr, alpha=0.2, color=f\"C{idx}\")\n",
    "\n",
    "ax.set_xlabel('Number of smile classifier evaluations')\n",
    "ax.set_ylabel('LPIPS score')\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"vis/ex5_lpips_evolution.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optdif1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
