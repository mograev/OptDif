{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2158ac5",
   "metadata": {},
   "source": [
    "This notebook compares the numbers that go in and out of components of this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02597e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.latent_models import LatentVQVAE\n",
    "import yaml\n",
    "\n",
    "# Configuration for the model\n",
    "model_config_path = \"../models/latent_vqvae/configs/sd35m_to_512d.yaml\"\n",
    "\n",
    "# Load model config\n",
    "with open(model_config_path, \"r\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "ckpt_path = \"../models/latent_vqvae/version_5/checkpoints/last.ckpt\"\n",
    "\n",
    "# Initialize model\n",
    "latent_vqvae = LatentVQVAE(\n",
    "    ddconfig=model_config[\"ddconfig\"],\n",
    "    lossconfig=model_config[\"lossconfig\"],\n",
    "    n_embed=model_config[\"embedconfig\"][\"n_embed\"],\n",
    "    embed_dim=model_config[\"embedconfig\"][\"embed_dim\"],\n",
    "    ckpt_path=ckpt_path,\n",
    "    monitor=\"val_total_loss\",\n",
    ")\n",
    "\n",
    "latent_vqvae.eval()\n",
    "latent_vqvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram that compares the input latents and the reconstructed latents\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Load the latents from the folder\n",
    "SD_LATENT_PATHS = glob.glob(os.path.join(\"../data/ffhq/sd_latents/\", \"*.pt\"))\n",
    "\n",
    "# Select 100 random latents\n",
    "random.seed(42)\n",
    "random.shuffle(SD_LATENT_PATHS)\n",
    "selected_paths = SD_LATENT_PATHS[:100]\n",
    "\n",
    "inputs = []\n",
    "reconstructions = []\n",
    "# Loop through the selected latents\n",
    "for path in selected_paths:\n",
    "    # Load the latent\n",
    "    sd_latent = torch.load(path, weights_only=False)\n",
    "    # Encode the latent using the LatentVQVAE\n",
    "    latent = latent_vqvae.encode(sd_latent.unsqueeze(0))[0]\n",
    "    # Decode the latent using the LatentVQVAE\n",
    "    recon = latent_vqvae.decode(latent).squeeze(0).detach()\n",
    "    # Store input and reconstructed latents\n",
    "    inputs.append(sd_latent)\n",
    "    reconstructions.append(recon)\n",
    "\n",
    "# Plot histograms for the input and reconstructed latents in one plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the tensors for histogram plotting\n",
    "input_flat = torch.cat([x.flatten() for x in inputs])\n",
    "recon_flat = torch.cat([x.flatten() for x in reconstructions])\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(input_flat.cpu().numpy(), bins=100, alpha=0.5, label='Input Latents', color='blue')\n",
    "plt.hist(recon_flat.cpu().numpy(), bins=100, alpha=0.5, label='Reconstructed Latents', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Input and Reconstructed Latents from VQ-VAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram that compares original latents and BO latents\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Load the latents from the folder\n",
    "SD_LATENT_PATHS = glob.glob(os.path.join(\"../data/ffhq/sd_latents/\", \"*.pt\"))\n",
    "\n",
    "# Select 100 random latents\n",
    "random.seed(42)\n",
    "random.shuffle(SD_LATENT_PATHS)\n",
    "selected_paths = SD_LATENT_PATHS[:100]\n",
    "\n",
    "input_latents = []\n",
    "# Loop through the selected latents\n",
    "for path in selected_paths:\n",
    "    # Load the latent\n",
    "    sd_latent = torch.load(path, weights_only=False)\n",
    "    # Encode the latent using the LatentVQVAE\n",
    "    latent = latent_vqvae.encode(sd_latent.unsqueeze(0))[0].squeeze().detach()\n",
    "    # Store the latent\n",
    "    input_latents.append(latent)\n",
    "\n",
    "bo_latents = []\n",
    "# Loop through the selected latents\n",
    "for iter in range(0, 90, 5):\n",
    "    for img in range(5):\n",
    "        # Load the latent\n",
    "        latent = torch.load(f\"../results/lso_gp_02/data/samples/iter_{iter}/latents/tensor_{img}.pt\", weights_only=False)\n",
    "        # Store the latent\n",
    "        bo_latents.append(latent)\n",
    "\n",
    "# Plot histograms for the input and reconstructed latents in one plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the tensors for histogram plotting\n",
    "input_flat = torch.cat([x.flatten() for x in input_latents])\n",
    "bo_flat = torch.cat([x.flatten() for x in bo_latents])\n",
    "\n",
    "print(input_flat.mean(), input_flat.std())\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(input_flat.cpu().numpy(), bins=100, alpha=0.5, label='Input Latents', color='blue')\n",
    "plt.hist(bo_flat.cpu().numpy(), bins=100, alpha=0.5, label='BO Latents', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Input and Output Latents from BO')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd94960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bo_latents = []\n",
    "# Loop through the selected latents\n",
    "for iter in range(0, 25, 5):\n",
    "    for img in range(5):\n",
    "        # Load the latent\n",
    "        latent = torch.load(f\"../results/debug_07/data/samples/iter_{iter}/latents/tensor_{img}.pt\", weights_only=False)\n",
    "        # Store the latent\n",
    "        bo_latents.append(latent)\n",
    "\n",
    "# Plot histograms for the input and reconstructed latents in one plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the tensors for histogram plotting\n",
    "bo_flat = torch.cat([x.flatten() for x in bo_latents])\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bo_flat.cpu().numpy(), bins=100, alpha=0.5, label='BO Latents', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Input and Output Latents from BO')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram that compares original latents and BO latents\n",
    "# Here we are not directly taking the latents, but re-encoding the SD latents\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Load the latents from the folder\n",
    "SD_LATENT_PATHS = glob.glob(os.path.join(\"../data/ffhq/sd_latents/\", \"*.pt\"))\n",
    "\n",
    "# Select 100 random latents\n",
    "random.seed(42)\n",
    "random.shuffle(SD_LATENT_PATHS)\n",
    "selected_paths = SD_LATENT_PATHS[:100]\n",
    "\n",
    "input_latents = []\n",
    "# Loop through the selected latents\n",
    "for path in selected_paths:\n",
    "    # Load the latent\n",
    "    sd_latent = torch.load(path, weights_only=False)\n",
    "    # Encode the latent using the LatentVQVAE\n",
    "    latent = latent_vqvae.encode(sd_latent.unsqueeze(0))[0].squeeze().detach()\n",
    "    # Store the latent\n",
    "    input_latents.append(latent)\n",
    "\n",
    "bo_latents = []\n",
    "# Loop through the selected latents\n",
    "for iter in range(0, 100, 5):\n",
    "    for img in range(5):\n",
    "        # Load the latent\n",
    "        sd_latent = torch.load(f\"../results/lso_dngo_03/data/sampled_data_iter{iter}/sd_latents/tensor_{img}.pt\", weights_only=False)\n",
    "        # Encode the latent using the LatentVQVAE\n",
    "        latent = latent_vqvae.encode(sd_latent.unsqueeze(0))[0].squeeze().detach()\n",
    "        # Store the latent\n",
    "        bo_latents.append(latent)\n",
    "\n",
    "# Plot histograms for the input and reconstructed latents in one plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the tensors for histogram plotting\n",
    "input_flat = torch.cat([x.flatten() for x in input_latents])\n",
    "bo_flat = torch.cat([x.flatten() for x in bo_latents])\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(input_flat.cpu().numpy(), bins=100, alpha=0.5, label='Input Latents', color='blue')\n",
    "plt.hist(bo_flat.cpu().numpy(), bins=100, alpha=0.5, label='BO Latents', color='orange')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Input and BO Latents from VQ-VAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c199012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "latent_grid = np.random.normal(loc=0.0, scale=0.3, size=(500, 512))\n",
    "\n",
    "print(f\"Min: {latent_grid.min()}, Max: {latent_grid.max()}, Mean: {latent_grid.mean()}, Std: {latent_grid.std()}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(latent_grid.flatten(), bins=100, alpha=0.5, label='Latent Grid', color='blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optdif1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
